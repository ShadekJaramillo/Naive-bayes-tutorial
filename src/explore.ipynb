{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import utils\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB, ComplementNB\n",
                "from sklearn.metrics import accuracy_score, recall_score\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "from math import ceil\n",
                "from pickle import dump"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Review classifier\n",
                "\n",
                "In this file we wil explore the creation of a model capable of classifying app reviews to determine if the reviews are positive or negative."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Database successfully loaded\n"
                    ]
                }
            ],
            "source": [
                "raw_df = utils.load_reviews_db()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>package_name</th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>index</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>886</th>\n",
                            "      <td>com.rovio.angrybirds</td>\n",
                            "      <td>loved it i loooooooooooooovvved it because it...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>887</th>\n",
                            "      <td>com.rovio.angrybirds</td>\n",
                            "      <td>all time legendary game the birthday party le...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>888</th>\n",
                            "      <td>com.rovio.angrybirds</td>\n",
                            "      <td>ads are way to heavy listen to the bad review...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>889</th>\n",
                            "      <td>com.rovio.angrybirds</td>\n",
                            "      <td>fun works perfectly well. ads aren't as annoy...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>890</th>\n",
                            "      <td>com.rovio.angrybirds</td>\n",
                            "      <td>they're everywhere i see angry birds everywhe...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>891 rows Ã— 3 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "               package_name  ... polarity\n",
                            "index                        ...         \n",
                            "0       com.facebook.katana  ...        0\n",
                            "1       com.facebook.katana  ...        0\n",
                            "2       com.facebook.katana  ...        0\n",
                            "3       com.facebook.katana  ...        0\n",
                            "4       com.facebook.katana  ...        0\n",
                            "...                     ...  ...      ...\n",
                            "886    com.rovio.angrybirds  ...        1\n",
                            "887    com.rovio.angrybirds  ...        1\n",
                            "888    com.rovio.angrybirds  ...        0\n",
                            "889    com.rovio.angrybirds  ...        1\n",
                            "890    com.rovio.angrybirds  ...        1\n",
                            "\n",
                            "[891 rows x 3 columns]"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "raw_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "polarity\n",
                            "0    584\n",
                            "1    307\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "raw_df.polarity.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data overview\n",
                "\n",
                "- Since we want our predictions to be based only on thee reviews we only need to work with the `review` variable.\n",
                "- The dataset is slightly unbalanced, for this reason it would be useful to evaluate the  quality of the models using the recall and accuracy metrics.\n",
                "- The text in each review may present things like trailing spaces and upper case letters so its recommended to format it before starting to process it.  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data formatting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = raw_df.copy()\n",
                "df[\"review\"] = raw_df[\"review\"].str.strip().str.lower()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Text vectorizing and train test splitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       ...,\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0]], shape=(712, 3310))"
                        ]
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "vec_model = CountVectorizer(stop_words = \"english\")\n",
                "\n",
                "x = df.review\n",
                "y = df.polarity\n",
                "\n",
                "x_train, x_test, y_train, y_test =train_test_split(x, y, test_size=0.2, random_state=42)\n",
                "\n",
                "x_train = vec_model.fit_transform(x_train).toarray()\n",
                "x_test = vec_model.transform(x_test).toarray()\n",
                "\n",
                "x_train"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model creation\n",
                "\n",
                "Our main focus is going to be creating a NaiveBayes model for classification.\n",
                "Since we vectorized the reviews using the CountVectorizer model, making our training data (counts of each word) discrete, and since the dataset is imbalanced, the appropriate Naive Bayes model for this case scenario is the Complement Naive Bayes."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initial model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "accuracy:   0.8044692737430168\n",
                        "recall:     0.660377358490566\n"
                    ]
                }
            ],
            "source": [
                "model = ComplementNB()\n",
                "model.fit(x_train, y_train)\n",
                "\n",
                "y_pred = model.predict(x_test)\n",
                "\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "rec_score = recall_score(y_test, y_pred)\n",
                "\n",
                "print(f'accuracy:   {acc_score}')\n",
                "print(f'recall:     {rec_score}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Is it the right model?\n",
                "\n",
                "In the next code cell we will check the accuracy and recall measurements of the other Naive Bayes implementations to confirm if the multinomial is indeed the best one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GaussianNB      accuracy: 0.8044692737430168\n",
                        "GaussianNB      recall:   0.6226415094339622\n",
                        "\n",
                        "BernoulliNB     accuracy: 0.770949720670391\n",
                        "BernoulliNB     recall:   0.39622641509433965\n",
                        "\n",
                        "MultinomialNB   accuracy: 0.8156424581005587\n",
                        "MultinomialNB   recall:   0.6037735849056604\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "models = {\n",
                "    'GaussianNB': GaussianNB(),\n",
                "    'BernoulliNB': BernoulliNB(),\n",
                "    'MultinomialNB': MultinomialNB()\n",
                "}\n",
                "\n",
                "for model_name, model in models.items():\n",
                "    model.fit(x_train, y_train)\n",
                "\n",
                "    y_pred = model.predict(x_test)\n",
                "\n",
                "    acc_score = accuracy_score(y_test, y_pred)\n",
                "    rec_score = recall_score(y_test, y_pred)\n",
                "\n",
                "    print(f'{model_name:15} accuracy: {acc_score}')\n",
                "    print(f'{model_name:15} recall:   {rec_score}\\n')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we take into account only the accuracy value, the best model would be MultinomialNB, nonetheless, the ComplementNB has a slightly lower accuracy but a much higher recall value. This means that ComplementNB is probably the best choice for creating our model.\n",
                "\n",
                "This result comes from the lesser assumptions that the ComplementNB has respect to the MultinomialNB implementation."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Parameter tunning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'alpha': 0.5, 'fit_prior': True, 'norm': False}\n",
                        "accuracy:   0.8044692737430168\n",
                        "recall:     0.660377358490566\n"
                    ]
                }
            ],
            "source": [
                "grid = {\n",
                "    'alpha':[0.001,0.4,0.5,0.6, 3],\n",
                "    'fit_prior':[True,False],\n",
                "    'norm':[True,False]\n",
                "}\n",
                "\n",
                "grid = GridSearchCV(model, grid, scoring='balanced_accuracy')\n",
                "grid.fit(x_train, y_train)\n",
                "\n",
                "y_pred = grid.best_estimator_.predict(x_test)\n",
                "params = grid.best_params_\n",
                "\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "rec_score = recall_score(y_test, y_pred)\n",
                "\n",
                "print(params)\n",
                "print(f'accuracy:   {acc_score}')\n",
                "print(f'recall:     {rec_score}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## saving the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os.path as path\n",
                "\n",
                "model_name = 'ComplementNB'\n",
                "param_string_list = ['_' + param.replace('_','') + '_' + str(value) \n",
                "                     for param, value in params.items()]\n",
                "model_name += ''.join(param_string_list) + '.sav'\n",
                "\n",
                "model_path = path.join('..','models',model_name)\n",
                "dump(grid.best_estimator_,open(model_path,'wb'))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Alternative models\n",
                "\n",
                "Since we managed to vectorize our data we can apply to it pretty much any classification model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "leaves:127\n",
                        "depth:72\n",
                        "accuracy:   0.7150837988826816\n",
                        "recall:     0.6037735849056604\n"
                    ]
                }
            ],
            "source": [
                "tree_model = DecisionTreeClassifier(random_state=42)\n",
                "tree_model.fit(x_train,y_train)\n",
                "y_pred = tree_model.predict(x_test)\n",
                "\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "rec_score = recall_score(y_test, y_pred)\n",
                "\n",
                "print(f'leaves:{tree_model.get_n_leaves()}')\n",
                "print(f'depth:{tree_model.get_depth()}')\n",
                "print(f'accuracy:   {acc_score}')\n",
                "print(f'recall:     {rec_score}')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As we can see, the code above created a pretty big decision tree, this means that the tree is probably overfitting our data, and hence causing the accuracy and recall measurements to drop respect to the Naive Bayes models."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Random forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "accuracy:   0.7988826815642458\n",
                        "recall:     0.7358490566037735\n"
                    ]
                }
            ],
            "source": [
                "RFC_model = RandomForestClassifier(random_state=42)\n",
                "RFC_model.fit(x_train,y_train)\n",
                "y_pred = RFC_model.predict(x_test)\n",
                "\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "rec_score = recall_score(y_test, y_pred)\n",
                "\n",
                "print(f'accuracy:   {acc_score}')\n",
                "print(f'recall:     {rec_score}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This solves the overfitting problem of the decision tree"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Logistic regression\n",
                "\n",
                "**Important note**: We do not need to normalize the values of the log model in this case and as it was tested, doing it would result in worse predicting capabilities for the model.\n",
                "This happens because all of our data has the same scale already (it is not like comparing kilometers centimeters, we are comparing counts of words for the same review comment), scaling the data in any way would result in a distortion of the data in ways that counteract the L2 regularization that is applied by sklearn to the logistic regression model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "accuracy:   0.8324022346368715\n",
                        "recall:     0.8113207547169812\n"
                    ]
                }
            ],
            "source": [
                "log_model = LogisticRegression(random_state=42)\n",
                "log_model.fit(x_train,y_train)\n",
                "y_pred = log_model.predict(x_test)\n",
                "\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "rec_score = recall_score(y_test, y_pred)\n",
                "\n",
                "print(f'accuracy:   {acc_score}')\n",
                "print(f'recall:     {rec_score}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is a surprising result. Given my superficial knowledge of the logistic regression model I couldn't come up with a strong explanation of why it performs better than Naive Bayes but I formulated some hypothesis anyway:\n",
                "- For this particular dataset and task the independency of the features does not hold worsening the Naive Bayes models predictions. In our case that means, the presence and amount of some words affect the presence and amount of some others. This has some chance of being true because those reviews have long sentences and that might be related to more complex grammatical structures.\n",
                "- The count of the words affect the odds of the review to be positive in an exponential way making the data fit very well the assumptions of the logistic regression model. This would happen for instance if the people giving negative reviews were more prone to just saying what they don't like with phrases like \"this is crap\" or \"it is broke and full of bugs\", and at the same time the people who leave positive reviews were prone to emphasize how much they liked the application using long descriptions and using epizeuxis (a repetition of a word or phrase in quick succession) in sentences like \"this is very very fun to play\".\n",
                "- It happened by chance because the dataset is fairly small, and if the dataset were bigger then the Naive Bayes model would outperform the logistic regression."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclussions\n",
                "\n",
                "- models reliant on probabilistic classification beat the tree-based ones, this may be due to the dataset containing few data clusters.\n",
                "- Even though Naive Bayes is usually better for text classification, in this case logistic regression is significantly better (specially in the recall score).\n",
                "- More tests and a deeper analysis are needed to understand why the logistic regression model worked better that the Naive Bayes ones.\n",
                "- Although doing a complete EDA was not necessary, it would be good for some text classification tasks like this one (it would have to be performed after the text vectorization) since multivariate analysis would help identifying if the independency of the features holds for our dataset."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
